\section{Introduction}

In last years unsupervised feature learning has become a good alternative to manually designing feature representations. The biggest problem is that many algorithms are difficult to use because they require to set a great number of hyper-parameters. Sparse filtering is a new feature learning algorithm which requires to set only the number of features to be learned.

We used the sparse filtering algorithm to train the first layers of our network in an unsupervised way. We will show that even with a small dataset it was able to generate filters and results similar to the ones obtained with Caffe.

\subsection{Sparse filtering}

The key idea of sparse filtering is to avoid explicit modeling of the data distribution: the algorithm works simply by optimizing the sparsity of the feature distribution. The input data is a matrix of floats where each row is a feature and each column represent one example. Sparse filtering wants to obtain 3 properties of the data distribution:
\begin{itemize}
\item \textbf{Population Sparsity:} each example should be represented by only few active features.
\item \textbf{Lifetime Sparsity:} each feature should be active only for a few example to be discriminative.
\item \textbf{High Dispersal:} the distribution of each row should be similar to the one of each other row.
\end{itemize}
They found that enforcing \textit{population sparsity} and \textit{high dispersal} was sufficient to learn good representations; \textit{lifetime sparsity} is implicitly obtained if you have the other two properties.

\subsubsection{Implementation}

Let \textit{\(f^{(i)}_{j}\)} represent the feature value for the \textit{\(i^{th}\)} example where \textbf{\textit{\(f^{(i)}_{j} = w_{j}^{T}x^{(i)}\)}}. For a dataset of M examples this gives us the sparse filtering objective function (~\ref{eq:sparse}):
\begin{equation}\label{eq:sparse}
minimize\,\sum_{i=1}^{M}\, \lVert \hat{f}^{(i)} \rVert _1\, =\, \sum_{i=1}^{M}\,\Bigg\|\,\frac{\tilde{f}^{(i)}}{\lVert\tilde{f}^{(i)}\rVert_2}\,\Bigg\| \,.
\end{equation}
Our algorithm works multiplying the weight matrix by the input data. The resulting matrix is normalized by row, then by column and finally we sums the absolute values of all cells. This value is used by the solver to check if the solution is improving or not.
To minimize the equation (~\ref{eq:sparse}) we used the scipy method \textit{minimize} with \textit{'L-BFGS-B'} as solver type. It receives as parameter the method described above and calls it several time until it reaches the maximum number of iterations.

The \textit{w} matrix that we obtain represent the input weights that should be assigned to the current convolutional layer to obtain the desired distribution.\\

Sparse filtering allows us to train each layer separately: using the input images we train the first convolutional layer, then we set its weights and forward all the pictures. The output data of \textit{layer 1} will then be used as input to train the second layer. These operations are repeated for the following layers until the entire network is trained. 

\subsubsection{Stopping criteria}

If any of these three conditions is verified the algorithm is stopped and the current result is returned:
\begin{itemize}
\item \textit{Number of iterations:} we set a maximum number of iterations after which the algorithm must terminate even if the convergence condition is not verified.
\item \textit{Not improving:} if the improvement between one iteration and the next one is too small the algorithm stops.
\item \textit{Convergence:} if the norm of the projected gradient is less than a value provided as a parameter to the \textit{minimize} function the convergence condition is satisfied
\end{itemize}
In every training attempt we obtained the the first, forth and fifth convolutional layers reached the maximum number of iterations while the second and third layers stopped after about 300 iterations because the norm of projected gradient was less than \(1*10^{-20}\). This behavior is observed with both 540, 1000 and 3000 input images.

\subsubsection{Results normalization}

For some layer the weights generated by sparse filtering were of the order of \(10^5\). This happens because the algorithm minimize only the dot product between the weights and the input data, so the weights can be arbitrarily big as long as the result of the multiplication is small.

Using too big weights has the problem that during the feed-forward phase the intermediate values obtained may be bigger than the maximum value representable using floats on 32 bits. Some of the values of the result matrices were always \textit{nan} which is the value used by \textit{numpy} to show that there was an error computing that value.

Our solution was to normalize the weights in the interval [-1.0 ; +1.0] dividing each value by the maximum number in absolute value present in the matrix. This way the distribution of the weights is not affected and the sparsity characteristics are maintained.

\subsection{Patches generation}

The examples contained in the feature matrix used as input by the sparse filtering algorithm are patches obtained from the output of the previous convolutional layer (from the input images in the case of the first layer). In the code is possible to specify how many should be taken for each image: they are randomly chosen between all possible patches that can be obtained from that picture.

A patch is a small area of the image which is then flattened to convert it from a 3-dimensional matrix to an array. There are several ways to flatten a matrix: you can for example choose to concatenate the rows or to concatenate the columns. These choices are all valid as long as you use then the corresponding inverse operation to recreate the original matrix when required.

In Decaf the patches extraction and linearization are already implemented in two C++ function \textit{im2col\_forward} and \textit{im2col\_backward} so we decided to use it. It receives the input data called \textit{padded\_data}, the kernel size \textit{\_ksize} and the \textit{stride}. The kernel size is the dimension of the patches whose shape will be (ksize, ksize, num. filters). The stride represent how many pixel this area where the patch is extracted should move between one patch and the following one.

\textit{Col\_data} is the output matrix which will contain all the patches flattened and transposed: each column of the matrix is a different patch.

\begin{lstlisting}[linewidth=8.0cm]
wrapper.im2col_forward(padded_data[i:i+1], col_data, self._ksize, self._stride)
\end{lstlisting}

\subsection{Decaf}

Decaf is a framework that implements convolutional neural networks, with the goal of being efficient and flexible. It was developed by the Berkeley Vision and Learning Center but it is not maintained anymore. Decaf is the predecessor of Caffe: the design pattern is similar and the outputs of the two networks are almost compatible.

The biggest difference is that Decaf is written in python and C++. This means that modify Decaf is easier and faster but the performances of the network are much worse with respect to caffe. Another problem is that there were no complete examples of deep convolutional neural network and the training algorithms were not complete.

One advantage of Decaf is that it is possible to train a network on CPU: you don't need to install the CUDA libraries and have a Nvidia graphic card. The training on CPU is much slower than on GPU but you can execute it on any computer even if it doesn't have a graphic card.

\subsubsection{Numpy and Scipy}

Decaf relies on the \textit{numpy} and \textit{scipy} python scientific packages: they provide N-dimensional arrays, optimization solvers and optimized linear algebra operations. To obtain the best performances they can be build from source and linked with the \textit{Intel MKL libraries}. Even with this improvements Decaf will still be about 10 times slower then Caffe in the training phase.

\section{The network} \label{sec:network}

The network we used has almost the same structure of the one used in the previous part. It is also an implementation of the network developed by Krizhevsky, Sutskevera and Hinton which won the 2012 edition of the ILSVRC-2012 competition.

In the original network they were using two GPUs in parallel (because the memory of one GPU was not sufficient to contain all the data) so they put half of the kernels (or neurons) on each GPU. The two half operations were executed in parallel to increase the network performances and the GPUs communicate only in certain layers to limit the amount of data exchanged between them.

Our code is not executed on GPUs and the RAM memory of our computer was big enough to contain all the data: the maximum amount of memory required is of about 14.5GB using 3000 images and 50 patches per image. Since this parallel execution was not required we substituted the \textit{Group Convolutional Layers} with normal \textit{Convolutional Layers}. This removed the overhead of splitting the data and then merging the results, slightly increasing the performance.

\subsection{Dataset}

We used the same dataset as the previous part which was extracted by the TrecVid dataset. We executed our experiments on the Adult annotation since it is quite balanced: the ratio of positive image is 25\% of all the images with information about the presence of an adult.

Our network requires a long time to train and we were able to use only few thousands of input images. Usually unsupervised learning algorithms are executed on millions of images so the performances of our network would be much worse than Caffe. To compensate this problem we trained the network on images already taken from the Adult dataset. The network will probably overfit, learning human like features, and the precision trying to recognize different types of objects will be much worse. For example we saw that this kind of network was not able to separate images of birds and cats (as will be described in section ~\ref{sec:birds_cats})\\

Unfortunately we were not able to compare the results of a network trained on this dataset and a network trained on generic images since training a network requires almost one week. On the machine that was assigned to us was possible to run only one training at a time because of memory and CPU limitations.

\section{Training}

\subsection{Unsupervised learning}

We used sparse filtering to train in an unsupervised way the first 5 layers. One good feature of unsupervised algorithms is that they allow to train the layers separately:  this reduces the complexity of the procedure and speeds up the learning phase.

The weight of the first layer are generated using as input the images loaded by the \textit{ImageDataLayer}. Then all the images are feed-forwarded through the first layer: its output is used to generate the patches which will be used to train the second convolutional layer. This operation is repeated for all the other layers until all of them are trained.

The fist layer has smaller filters than the last four: this implies that training the first layer is much faster than the others because the intermediate matrices are much smaller, which implies that the dot product operation is faster. In Table \ref{tbl:train_time_per_layer} you can see the dimensions of the filters and the training time using 3000 input images and 50 patches per image.\\

The first two number used to compute the kernel dimension are the dimension of the patches that will be retrieved from the input data and the third value is the number of neurons of the previous convolutional layer (this value is 3 for \textit{conv1} because it represent the RGB components of the image).

Even when the kernel dimension is the same the training times are slightly different: this depends both on the distribution of the data received (if there are many zeros the dot product is faster) and the workload of the computer. We were running several scripts in parallel so the load on the machine (and consequently its performance) was not constant.

We assigned to the forth and fifth layers a different number of maximum iterations: specifically it is one third of the number of iteratins of the first 3 layers. We made this choice since the last two layer have big kernels and would require a even longer time to train. We haven't changed this value for the second and third layer even if they also have big kernels since they converge after 300 iterations.\\

The feed-forward time represent the total time required to forward the images through the preceding layers and extract the patches. There is a big difference between the times associated with \textit{conv1, conv2} and \textit{conv3} while the last two values are similar to the \textit{conv2} one. This happens because the first two layers are more complex: all layers contain a \textit{ConvolutionLayer} and a \textit{ReluLayer} but the first two contain also a \textit{PoolingLayer} and a \textit{LocalResponseNormalizeLayer}. These two additional layers add some overhead to the feed-forward operation, in particular the normalization phase is computationally expensive.\\

Table ~\ref{tbl:train_time} shows the training time for different values of input images and patches extracted. The number of iterations is fixed at 1800 and also the number of patches per image is almost constant at about 50. The time required to train the network with sparse filtering is almost linear in the number of images. It is 2 days with 1000 images and it is 6 days with 3000.

\begin{figure}[h!]\centering
    \includegraphics[width=\linewidth]{images/net/features_1000}
    \caption{First layer filters}
    \label{fig:filters}
\end{figure}


\begin{table*}[htbp]
\caption{Training time per layer}
\centering
\begin{tabular}{lccccc}
    Layer       & kernel dimension & Feed-forward time & Iterations & Training time \\
    \midrule
    conv1        & 11*11*3 = 363  & 0h 1m 22s & 1800  & 5h 33m 20s \\
    conv2     & 5*5*96 = 2400  & 0h 30m 3s & 327 & 15h 39m 20s \\
    conv3          & 3*3*256 = 2304 & 1h 31m 54s & 328 & 21h 1m 10s \\
    conv4        & 3*3*384 = 3456 & 1h 39m 45s & 600 & 41h 55m 0s \\
    conv5          & 3*3*384 = 3456  & 2h 2m 55s & 600 & 34h 51m 40s \\
\end{tabular}
\label{tbl:train_time_per_layer}
\end{table*}

\begin{table*}[htbp]
\caption{Total training time (unsupervised only)}
\centering
\begin{tabular}{lccc}
    Number of images  & Number of patches & Max. iterations & Training time \\
    \midrule
    540 & 60 &1800 & 0d 20h 16m 53s \\
    1000 & 50 & 1800 & 2d 2h 23m 00s \\
    3000 & 50 & 1800 & 6d 2h 30m 00s \\
\end{tabular}
\label{tbl:train_time}
\end{table*}

\begin{figure*}[hbtp]\centering
\centering
\begin{subfigure}[t]{.4\textwidth}
    \centering
    \includegraphics[width=.8\linewidth]{images/bird_1}
    \caption{Input image}
    \label{fig:output1b}
\end{subfigure}%
\begin{subfigure}[t]{.4\textwidth}
    \centering
    \includegraphics[width=.8\linewidth]{images/net/output_1}
    \caption{First layer output}
    \label{fig:output2b}
\end{subfigure}
\begin{subfigure}[t]{.4\textwidth}
    \centering
    \includegraphics[width=.8\linewidth]{images/net/filters_2}
    \caption{Second layer filters}
    \label{fig:output3b}
\end{subfigure}%
\begin{subfigure}[t]{.4\textwidth}
    \centering
    \includegraphics[width=.8\linewidth]{images/net/output_2}
    \caption{Second layer output}
    \label{fig:output3boh}
\end{subfigure}
\caption{Processing of an image taken from ImageNet}
\label{fig:outputb}
\end{figure*}

\subsection{Supervised learning}

The network described in section ~\ref{sec:network} includes 8 layers: 5 unsupervised and 3 supervised. The last three layers should be trained with the \textit{back-propagation algorithm}. This phase would allow to use this network to recognize objects inside the images.

In the training phase the \textit{ImageDataLayer} outputs both the image data and the associated label. This label is then retrieved by the \textit{KLDivergenceLossLayer} which computes the difference between the predicted label and the correct one.

During the execution phase the network outputs an array of float which represent the probability that object\_i appears in the image. From this array the 5 highest probabilities are extracted and printed on the screen.\\

For our experiments we used only the unsupervised part. For each image sent through the network, each layer writes its output in a file with the format required by libSVM (part I section ~\ref{subsec:svm_input}).
When all the images were processed we scaled the output files using the software \textit{svm-scale} (already provided by libSVM) and then we trained the Support Vector Machine using the training scaled data. The model created is then used to evaluate the validation images.

Since this operation must be executed for all input files we created a bash script to automate these operations. The scale operation is really long (takes several hours even for just 3000 images) so the scaling of the train and test data is executed in parallel. In Table ~\ref{tbl:scale_time} you can see the average scaling time for the training and validation data: since they are executed in parallel the total time is just equal to the biggest one which is just about the 65\% of the time required executing the two operations sequentially.

For the training phase we used 1000 images randomly chosen inside the train folder and for the test phase we used 5218 images randomly chosen inside the test folder.

\begin{table*}[htbp]
\caption{Scaling time}
\centering
\begin{tabular}{lccc}
    Phase  & folder & Num. of images & Average scaling time \\
    \midrule
    Training & train & 3000 & 3h 46m 53s \\
    Validation & test & 5218 & 7h 00m 52s \\
    \\
    Version & Num. of images & Total time & Improvement \\
    \midrule
    Sequential & 7218 & 11h 10m 45s & 0\% \\
    Parallel & 7218 & 07h 23m 52s & -35\% \\
\end{tabular}
\label{tbl:scale_time}
\end{table*}

%\begin{lstlisting}[linewidth=8.5cm]
%for i in {1..6}
%do
%    echo "Iteration: $i"
%    echo "Scaling.."
%    if [ ! -f "$FOLDER/plibsvm_$i.train" ]; then
%        ./svm-scale -s tmp.txt $NET_FOLDER/plibsvm_$i.train > "$FOLDER/plibsvm_$i.train" &
%    fi
%    if [ ! -f "$FOLDER/plibsvm_$i.val" ]; then
%        ./svm-scale -r tmp.txt $NET_FOLDER/plibsvm_$i.val > "$FOLDER/plibsvm_$i.val" &
%    fi
%    wait
%    echo "Training.."
%    ./svm-train -b 1 -t 1 -d 3 -g 0.0078125 "$FOLDER/plibsvm_$i.train" "$FOLDER/plibsvm_$i.model"
%    echo "Predict.."
%    ./svm-predict -b 1 "$FOLDER/plibsvm_$i.val" "$FOLDER/plibsvm_$i.model" "$FOLDER/plibsvm_$i.out"
%    python saved/precision.py "$FOLDER/plibsvm_$i.val" "$FOLDER/plibsvm_$i.out" &> "$FOLDER/plibsvm_$i.prec"
%done
%\end{lstlisting}

\subsection{Birds and cats} \label{sec:birds_cats}

We downloaded from ImageNet pictures relative to the synsets cat and bird. We trained our network using sparse filtering on 540 images randomly chosen between them. Then we executed the network on 600 images (different from the training ones) writing the output of the fifth layer in a file.

This output file was the processed by a modified t-SNE implementation to plot the values in 2D. As we can see from Picture ~\ref{fig:bird_cat} even with few training images the network is able to find useful features that allow to correctly separate the images of birds and cats. Obviously the division is not perfect since we trained the network with just 540 pictures and we didn't execute the back-propagation algorithm to fine tuning the weights.


\begin{figure}[h!]\centering
\includegraphics[width=\linewidth]{images/distribution}
\vspace{10pt}
\caption{Example images from ImageNet.}
\label{fig:bird_cat}
\end{figure}

\section{Measurements}

We used libSVM to classify the data generated from the neural network using the Adult annotation. We considered only the images which had an information associated about the presence or absence of an Adult (indicated with a P or a N in the Adult.ann file). We used as model the \textit{polinomial of degree 3}.\\

In Table ~\ref{tbl:meas_sparse} are reported the results using the model generated training the network with 1000 images. These values are lower than the one resulting from the same experiment using Caffe but have similar characteristics. Like the previous results also here the precision is almost constant on all layer with the same k. For example with k=2000 the values are all close to 0.60, they are not decreasing in the lower layers.\\

In Table ~\ref{tbl:meas_sparse_3k} you can see the results obtained using the network trained on 3000 images. The results are slightly better then the previous ones but still worse than Caffe's results. One strange thing is that the precision here is higher in the lower layers (close to \textit{conv1}) than in the upper ones.

This may be caused by the decision to reduce the number of iterations for the last layers.

\begin{table*}[htbp]
\caption{Results on Adult annotation - 1000 images}
\centering
\begin{tabular}{lccccccc}
    Layer       & $k=100$ & $k=500$ & $k=1000$ & $k=1500$ &
    $k=2000$ & $k=2500$ \\
    \midrule
    pool5        & 0.69 & 0.71 & 0.68 & 0.66 & 0.62 & 0.60 \\
    conv5\_neuron        & 0.75 & 0.68 & 0.63 & 0.59 & 0.56 & 0.54 \\
    conv4\_neuron      & 0.61 & 0.66 & 0.62 & 0.59 & 0.56 & 0.54 \\
    conv3\_neuron        & 0.73 & 0.73 & 0.69 & 0.66 & 0.63 & 0.61 \\
    norm2        & 0.72 & 0.75 & 0.73 & 0.72 & 0.69 & 0.65 \\
    norm1        & 0.76 & 0.75 & 0.74 & 0.72 & 0.61 & 0.68 \\
\end{tabular}
\label{tbl:meas_sparse}
\end{table*}

\begin{table*}[htbp]
\caption{Results on Adult annotation - 3000 images}
\centering
\begin{tabular}{lccccccc}
    Layer       & $k=100$ & $k=500$ & $k=1000$ & $k=1500$ &
    $k=2000$ & $k=2500$ \\
    \midrule
    pool5        & 0.79 & 0.68 & 0.71 & 0.70 & 0.67 & 0.69 \\
    conv5\_neuron         & 0.77 & 0.66 & 0.69 & 0.69 & 0.66 & 0.65 \\
    conv4\_neuron       & 0.77 & 0.68 & 0.71 & 0.69 & 0.67 & 0.66 \\
    conv3\_neuron        & 0.80 & 0.70 & 0.73 & 0.71 & 0.69 & 0.69 \\
    norm2        & 0.81 & 0.72 & 0.75 & 0.69 & 0.72 & 0.71 \\
    norm1        & 0.83 & 0.72 & 0.76 & 0.71 & 0.73 & 0.72 \\
\end{tabular}
\label{tbl:meas_sparse_3k}
\end{table*}

\section{Considerations}

The biggest problem of this network is its performances. It would be impossible to train the network with 100.000 images or millions since it would require months.

One possibility would be to build from source numpy and scipy and integrate the Intel MKL libraries. This can improve the network speed of about 2 times. Another improvement would be to use a profiler to find the bottlenecks in the code and improve those algorithms (or at least check that there are not useless operations). \\

The results obtained with this network are not particularly good but in our opinion if it would be possible to train it with more images and for a longer time the results will improve greatly. However even from these experiments is possible to see that the sparse filtering algorithm is converging and is able to obtain good features from the input data which can be used to classify them.

The filters of the first layer are also really similar to the one present in Caffe.

% different number of images

